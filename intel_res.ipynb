{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672ea068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as trans\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abf32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate pixel \n",
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48574597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionModel(\n",
       "  (model): Sequential(\n",
       "    (0): C_ADD(\n",
       "      (conv): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (3): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Conv(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (5): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-3): 4 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Conv(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (7): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-3): 4 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Conv(\n",
       "      (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (9): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): SPPF(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (15): Concat()\n",
       "    (16): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): Conv(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (18): Concat()\n",
       "    (19): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): Conv(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (21): Concat()\n",
       "    (22): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): Detect(\n",
       "      (cv2): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(576, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(1152, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(960, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (cv3): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 17, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(1152, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 17, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(960, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 17, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (dfl): DFL(\n",
       "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('best.pt')['model'].to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2bbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov8\n",
    "def xywh2xyxy(x):\n",
    "        assert x.shape[-1] == 4, f'input shape last dimension expected 4 but input shape is {x.shape}'\n",
    "        y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)  # faster than clone/copy\n",
    "        dw = x[..., 2] / 2  # half-width\n",
    "        dh = x[..., 3] / 2  # half-height\n",
    "        y[..., 0] = x[..., 0] - dw  # top left x\n",
    "        y[..., 1] = x[..., 1] - dh  # top left y\n",
    "        y[..., 2] = x[..., 0] + dw  # bottom right x\n",
    "        y[..., 3] = x[..., 1] + dh  # bottom right y\n",
    "        return y\n",
    "def non_max_suppression(\n",
    "            prediction,\n",
    "            conf_thres=0.001,\n",
    "            iou_thres=0.8,\n",
    "            classes=None,\n",
    "            agnostic=False,\n",
    "            multi_label=True,\n",
    "            labels=(),\n",
    "            max_det=300,\n",
    "            nc=17,  # number of classes (optional)\n",
    "            max_time_img=0.05,\n",
    "            max_nms=30000,\n",
    "            max_wh=math.inf,\n",
    "):\n",
    "        assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
    "        assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
    "        if isinstance(prediction, (list, tuple)):  # YOLOv8 model in validation model, output = (inference_out, loss_out)\n",
    "            prediction = prediction[0]  # select only inference output\n",
    "    \n",
    "        device = prediction.device\n",
    "        mps = 'mps' in device.type  # Apple MPS\n",
    "        if mps:  # MPS not fully supported yet, convert tensors to CPU before NMS\n",
    "            prediction = prediction.cpu()\n",
    "        bs = prediction.shape[0]  # batch size\n",
    "        nc = nc or (prediction.shape[1] - 4)  # number of classes\n",
    "        nm = prediction.shape[1] - nc - 4\n",
    "        mi = 4 + nc  # mask start index\n",
    "        xc = prediction[:, 4:mi].amax(1) > conf_thres  # candidates\n",
    "    \n",
    "        # Settings\n",
    "        # min_wh = 2  # (pixels) minimum box width and height\n",
    "        time_limit = 0.5 + max_time_img * bs  # seconds to quit after\n",
    "        multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    \n",
    "        prediction = prediction.transpose(-1, -2)  # shape(1,84,6300) to shape(1,6300,84)\n",
    "        prediction[..., :4] = xywh2xyxy(prediction[..., :4])  # xywh to xyxy\n",
    "        output = [torch.zeros((0, 6 + nm), device=prediction.device)] * bs\n",
    "        for xi, x in enumerate(prediction):  # image index, image inference\n",
    "            # Apply constraints\n",
    "            # x[((x[:, 2:4] < min_wh) | (x[:, 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "            x = x[xc[xi]]  # confidence\n",
    "    \n",
    "            # Cat apriori labels if autolabelling\n",
    "            if labels and len(labels[xi]):\n",
    "                lb = labels[xi]\n",
    "                v = torch.zeros((len(lb), nc + nm + 4), device=x.device)\n",
    "                v[:, :4] = xywh2xyxy(lb[:, 1:5])  # box\n",
    "                v[range(len(lb)), lb[:, 0].long() + 4] = 1.0  # cls\n",
    "                x = torch.cat((x, v), 0)\n",
    "    \n",
    "            # If none remain process next image\n",
    "            if not x.shape[0]:\n",
    "                continue\n",
    "    \n",
    "            # Detections matrix nx6 (xyxy, conf, cls)\n",
    "            box, cls, mask = x.split((4, nc, nm), 1)\n",
    "    \n",
    "            if multi_label:\n",
    "                i, j = torch.where(cls > conf_thres)\n",
    "                x = torch.cat((box[i], x[i, 4 + j, None], j[:, None].float(), mask[i]), 1)\n",
    "            else:  # best class only\n",
    "                conf, j = cls.max(1, keepdim=True)\n",
    "                x = torch.cat((box, conf, j.float(), mask), 1)[conf.view(-1) > conf_thres]\n",
    "    \n",
    "            # Filter by class\n",
    "            if classes is not None:\n",
    "                x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "    \n",
    "            # Check shape\n",
    "            n = x.shape[0]  # number of boxes\n",
    "            if not n:  # no boxes\n",
    "                continue\n",
    "            if n > max_nms:  # excess boxes\n",
    "                x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence and remove excess boxes\n",
    "    \n",
    "            # Batched NMS\n",
    "            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
    "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "            i = i[:max_det]  # limit detections\n",
    "    \n",
    "    \n",
    "            output[xi] = x[i]\n",
    "            if mps:\n",
    "                output[xi] = output[xi].to(device)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565d0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscapesid2trainid = {\n",
    "    0: -1, 1: -1, 2: -1, 3: -1, 4:-1, 5: -1, 6: -1, 7: 0, 8: 1, 9: 2, 10: 3, 11: 4, 12: 5, 13: 6, 14: 7,15: -1, 16: -1,17: 8, \n",
    "    18: -1, 19: 9, 20: 10,21: -1, 22: -1, 23: -1, 24: 11,25: 11, 26: 12,27: 21, 28: 12, 29: 12, 30: 13, 31: 14, 32: 15, 33: 16, -1: -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b14e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_preprocess(target, mapping):\n",
    "    for origin in mapping.keys():\n",
    "        target = torch.where(target == origin, mapping[origin], target)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e92e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(class_id, pred, target, padding=(0, (2048-1024)/2)):\n",
    "    # pred is in the form of(x1, y1, x2, y2, conf, class_id)\n",
    "    prediction = torch.full(fill_value=-1, size=(target.shape[-1], target.shape[-2]), device=target.device)\n",
    "    prediction.fill_(-1)\n",
    "    target = torch.where(target == class_id, class_id, -1)\n",
    "    pred_ = pred.clone()\n",
    "    pred_[:, (0, 2)] -= padding[0]\n",
    "    pred_[:, (1, 3)] -= padding[1]\n",
    "    for p in pred_:\n",
    "        if p[-1] == class_id:\n",
    "            prediction[int(p[1]+0.5):int(p[3]+0.5), int(p[0]+0.5): int(p[2]+0.5)] = class_id\n",
    "    prediction = prediction.permute([1, 0])\n",
    "    tp = torch.where((target == class_id)*(prediction ==class_id), 1, 0).sum()\n",
    "    fp = torch.where((prediction == class_id) * (target == -1), 1, 0).sum()\n",
    "    tn = torch.where((target == -1) * (prediction == -1), 1, 0).sum()\n",
    "    fn = target.shape[-1] * target.shape[-2] - tp - fp - tn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov8\n",
    "def letter_box(img=None):\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    new_shape = [2048, 2048]\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)) , int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)) , int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                                 value=(114, 114, 114))  # add border\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b2449c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.dataset import YOLODataset\n",
    "from ultralytics.data.build import InfiniteDataLoader\n",
    "from ultralytics.utils import IterableSimpleNamespace\n",
    "from pathlib import WindowsPath\n",
    "from ultralytics.data.utils import PIN_MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9401ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'img_path': 'D:\\\\dev\\\\ultralytics\\\\yolo_format\\\\cityscapes\\\\val',\n",
    "       'imgsz': 2048,\n",
    "       'batch_size': 10,\n",
    "       'augment': False,\n",
    "       'hyp':\n",
    "       IterableSimpleNamespace(\n",
    "           task='detect',\n",
    "           mode='val',\n",
    "           model='D:\\\\anaconda3\\\\jupyter notebook dir\\\\best.pt',\n",
    "           data='D:\\\\dev\\\\ultralytics\\\\cityscapes.yaml',\n",
    "           epochs=1,\n",
    "           patience=50,\n",
    "           batch=10,\n",
    "           imgsz=2048,\n",
    "           save=True,\n",
    "           save_period=-1,\n",
    "           cache=False,\n",
    "           device='cpu',\n",
    "           workers=0,\n",
    "           project={},\n",
    "           name={},\n",
    "           exist_ok=False,\n",
    "           pretrained=False,\n",
    "           optimizer='auto',\n",
    "           verbose=True,\n",
    "           seed=0,\n",
    "           deterministic=True,\n",
    "           single_cls=False,\n",
    "           rect=False,\n",
    "           cos_lr=False,\n",
    "           close_mosaic=10,\n",
    "           resume=False,\n",
    "           fraction=1.0,\n",
    "           profile=False,\n",
    "           freeze='None',\n",
    "           overlap_mask=True,\n",
    "           mask_ratio=4,\n",
    "           dropout=0.0,\n",
    "           val=True,\n",
    "           split='val',\n",
    "           save_json=False,\n",
    "           save_hybrid=False,\n",
    "           conf=0.5,\n",
    "           iou=0.7,\n",
    "           max_det=300,\n",
    "           half=False,\n",
    "           dnn=False,\n",
    "           plots=True,\n",
    "           source={},\n",
    "           show=False,\n",
    "           save_txt=False,\n",
    "           save_conf=False,\n",
    "           save_crop=False,\n",
    "           show_labels=True,\n",
    "           show_conf=True,\n",
    "           vid_stride=1,\n",
    "           stream_buffer=False,\n",
    "           line_width=8, \n",
    "           visualize=False,\n",
    "           augment=False,\n",
    "           agnostic_nms=False,\n",
    "           classes={},\n",
    "           retina_masks=False,\n",
    "           boxes=True),\n",
    "       'rect': False,\n",
    "       'cache': None,\n",
    "       'single_cls': False,\n",
    "       'stride': 32,\n",
    "       'pad': 0.5,\n",
    "       'prefix': '\\x1b[34m\\x1b[1mval: \\x1b[0m', 'classes': {},\n",
    "       'fraction': 1.0\n",
    "    }\n",
    "data = {'val': 'D:\\\\dev\\\\ultralytics\\\\yolo_format\\\\cityscapes\\\\val',\n",
    "        'train': 'D:\\\\',\n",
    "        'names': {0: 'road', 1: 'sidewalk', 2: 'parking', 3: 'rail track', 4: 'building', 5: 'wall', 6: 'fence', 7: 'guard rail', 8: 'pole', 9: 'traffic light', 10: 'traffic sign', 11: 'person', 12: 'car', 13: 'trailer', 14: 'train', 15: 'motorcycle', 16: 'bicycle'},\n",
    "        'yaml_file': 'D:\\\\dev\\\\ultralytics\\\\cityscapes.yaml',\n",
    "        'nc': 17,\n",
    "        'path': WindowsPath('D:/dev/ultralytics')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ca3430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\119.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\163.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\176.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\256.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\280.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\329.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\352.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\355.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\366.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\373.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\375.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\382.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\392.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\396.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\404.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\406.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\41.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\416.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\434.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\441.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\466.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\467.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\468.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\470.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\493.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\97.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\dev\\ultralytics\\yolo_format\\cityscapes\\val\\images\\99.png: 1 duplicate labels removed\n"
     ]
    }
   ],
   "source": [
    "dataset = YOLODataset(\n",
    "    img_path='D:\\\\dev\\\\ultralytics\\\\yolo_format\\\\cityscapes\\\\val',\n",
    "    imgsz=2048,\n",
    "    batch_size=1,\n",
    "    augment=False,\n",
    "    hyp=cfg['hyp'],\n",
    "    rect=False,\n",
    "    cache=None,\n",
    "    single_cls=False,\n",
    "    stride=32,\n",
    "    pad=0.5,\n",
    "    use_segments=False,\n",
    "    use_keypoints=False,\n",
    "    classes=(),\n",
    "    data=data,\n",
    "    fraction=1.0\n",
    ")\n",
    "dataloader = InfiniteDataLoader(dataset=dataset,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=1,\n",
    "                              sampler=None,\n",
    "                              pin_memory=PIN_MEMORY,\n",
    "                              collate_fn=getattr(dataset, 'collate_fn', None),\n",
    "                              worker_init_fn=None,\n",
    "                              generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491ef605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x):\n",
    "    x = cv2.cvtColor(numpy.asarray(x),cv2.COLOR_RGB2BGR) \n",
    "    x = letter_box(x)\n",
    "    x = trans.ToTensor()(x)\n",
    "    return x.permute([0, 2, 1])\n",
    "\n",
    "src_trans = trans.Compose([\n",
    "    preprocess\n",
    "])\n",
    "test_data = torchvision.datasets.Cityscapes(root='D:/anaconda3/Lib/site-packages/cityscapesscripts/download/',\n",
    "                                           split='val',\n",
    "                                           mode='fine',\n",
    "                                           target_type='semantic',\n",
    "                                           target_transform=trans.ToTensor(),\n",
    "                                           transform=src_trans)\n",
    "print(test_data[0][0].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b81c0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [56:59,  6.84s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "preds = None\n",
    "metrics = [Accumulator(4) for i in range(17)]\n",
    "total = Accumulator(4)\n",
    "for idx, batch in tqdm(enumerate(dataloader)):\n",
    "    preds = model(batch['img'].to(device).half()/255.0)\n",
    "    res = non_max_suppression(preds)\n",
    "    for i in range(0, 17):\n",
    "        target = target_preprocess(test_data[idx][1].permute([0, 2, 1])*255, cityscapesid2trainid).clone().to(device)\n",
    "        metric = evaluate(i, res[batch_size-1], target)\n",
    "        total.add(metric)\n",
    "        metrics[i].add(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e99e9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2708139603883966\n"
     ]
    }
   ],
   "source": [
    "print((0.0 + total[0])/(total[0] + total[1] + total[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce4a6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(accmulator):\n",
    "    return (0.0 + accmulator[0]) / (accmulator[0] + accmulator[1] + accmulator[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b0a7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PA(accmulator):\n",
    "    return (0.0 + accmulator[0] + accmulator[2]) / (accmulator[0] + accmulator[1] +accmulator[2] + accmulator[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d7fa782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 : IoU:0.48552970388835365, PA:0.7279142150878907\n",
      "label 1 : IoU:0.08947700874469611, PA:0.8056015195846558\n",
      "label 2 : IoU:0.00768193270175575, PA:0.96415696144104\n",
      "label 3 : IoU:0.0, PA:0.9946085271835328\n",
      "label 4 : IoU:0.27010629767401745, PA:0.6530777482986451\n",
      "label 5 : IoU:0.007199373473069394, PA:0.9738247804641723\n",
      "label 6 : IoU:0.020684682738711425, PA:0.9808716325759887\n",
      "label 7 : IoU:0.0, PA:0.9997403831481934\n",
      "label 8 : IoU:0.020121417051213557, PA:0.9508402137756348\n",
      "label 9 : IoU:0.004320607635808001, PA:0.9960992450714111\n",
      "label 10 : IoU:0.007547349887377524, PA:0.9869889640808105\n",
      "label 11 : IoU:0.029209640843936544, PA:0.9630387487411499\n",
      "label 12 : IoU:0.1216936621495841, PA:0.8831227807998657\n",
      "label 13 : IoU:0.0, PA:0.9996036043167115\n",
      "label 14 : IoU:0.003194779316257256, PA:0.9965126371383667\n",
      "label 15 : IoU:8.068672562841587e-05, PA:0.9978963041305542\n",
      "label 16 : IoU:0.01680004317676792, PA:0.9848852472305298\n"
     ]
    }
   ],
   "source": [
    "for i in range(17):\n",
    "    print(f'label {i} : IoU:{IoU(metrics[i])}, PA:{PA(metrics[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bb37e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: IoU:0.2708139603883966, PA:0.9328696184158325\n"
     ]
    }
   ],
   "source": [
    "print(f'Total: IoU:{IoU(total)}, PA:{PA(total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec511a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 18:36:01 [INFO] Start auto tuning.\n",
      "2023-10-24 18:36:01 [INFO] Quantize model without tuning!\n",
      "2023-10-24 18:36:01 [INFO] Quantize the model with default configuration without evaluating the model.                To perform the tuning process, please either provide an eval_func or provide an                    eval_dataloader an eval_metric.\n",
      "2023-10-24 18:36:01 [INFO] Adaptor has 5 recipes.\n",
      "2023-10-24 18:36:01 [INFO] 1 recipes specified by user.\n",
      "2023-10-24 18:36:01 [INFO] 3 recipes require future tuning.\n",
      "2023-10-24 18:36:01 [INFO] *** Initialize auto tuning\n",
      "Exception in thread 2023-10-24 18:36:01 [INFO] {\n",
      "2023-10-24 18:36:01 [INFO]     'PostTrainingQuantConfig': {\n",
      "Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "2023-10-24 18:36:01 [INFO]         'AccuracyCriterion': {\n",
      "2023-10-24 18:36:01 [INFO]             'criterion': 'relative',\n",
      "2023-10-24 18:36:01 [INFO]             'higher_is_better': True,\n",
      "    self.run()\n",
      "  File \"D:\\anaconda3\\lib\\threading.py\", line 1304, in run\n",
      "2023-10-24 18:36:01 [INFO]             'tolerable_loss': 0.01,\n",
      "2023-10-24 18:36:01 [INFO]             'absolute': None,\n",
      "2023-10-24 18:36:01 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x0000014821356670>>,\n",
      "    self.finished.wait(self.interval)\n",
      "  File \"D:\\anaconda3\\lib\\threading.py\", line 581, in wait\n",
      "2023-10-24 18:36:01 [INFO]             'relative': 0.01\n",
      "2023-10-24 18:36:01 [INFO]         },\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"D:\\anaconda3\\lib\\threading.py\", line 316, in wait\n",
      "2023-10-24 18:36:01 [INFO]         'approach': 'post_training_static_quant',\n",
      "2023-10-24 18:36:01 [INFO]         'backend': 'default',\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "OverflowError: timeout value is too large\n",
      "2023-10-24 18:36:01 [INFO]         'calibration_sampling_size': [\n",
      "2023-10-24 18:36:01 [INFO]             100\n",
      "2023-10-24 18:36:01 [INFO]         ],\n",
      "2023-10-24 18:36:01 [INFO]         'device': 'cpu',\n",
      "2023-10-24 18:36:01 [INFO]         'diagnosis': False,\n",
      "2023-10-24 18:36:01 [INFO]         'domain': 'auto',\n",
      "2023-10-24 18:36:01 [INFO]         'example_inputs': None,\n",
      "2023-10-24 18:36:01 [INFO]         'excluded_precisions': [\n",
      "2023-10-24 18:36:01 [INFO]         ],\n",
      "2023-10-24 18:36:01 [INFO]         'framework': 'pytorch_fx',\n",
      "2023-10-24 18:36:01 [INFO]         'inputs': [\n",
      "2023-10-24 18:36:01 [INFO]         ],\n",
      "2023-10-24 18:36:01 [INFO]         'model_name': '',\n",
      "2023-10-24 18:36:01 [INFO]         'ni_workload_name': 'quantization',\n",
      "2023-10-24 18:36:01 [INFO]         'op_name_dict': None,\n",
      "2023-10-24 18:36:01 [INFO]         'op_type_dict': None,\n",
      "2023-10-24 18:36:01 [INFO]         'outputs': [\n",
      "2023-10-24 18:36:01 [INFO]         ],\n",
      "2023-10-24 18:36:01 [INFO]         'quant_format': 'default',\n",
      "2023-10-24 18:36:01 [INFO]         'quant_level': 'auto',\n",
      "2023-10-24 18:36:01 [INFO]         'recipes': {\n",
      "2023-10-24 18:36:01 [INFO]             'smooth_quant': True,\n",
      "2023-10-24 18:36:01 [INFO]             'smooth_quant_args': {\n",
      "2023-10-24 18:36:01 [INFO]                 'alpha': 0.5\n",
      "2023-10-24 18:36:01 [INFO]             },\n",
      "2023-10-24 18:36:01 [INFO]             'layer_wise_quant': False,\n",
      "2023-10-24 18:36:01 [INFO]             'layer_wise_quant_args': {\n",
      "2023-10-24 18:36:01 [INFO]             },\n",
      "2023-10-24 18:36:01 [INFO]             'fast_bias_correction': False,\n",
      "2023-10-24 18:36:01 [INFO]             'weight_correction': False,\n",
      "2023-10-24 18:36:01 [INFO]             'gemm_to_matmul': True,\n",
      "2023-10-24 18:36:01 [INFO]             'graph_optimization_level': None,\n",
      "2023-10-24 18:36:01 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2023-10-24 18:36:01 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2023-10-24 18:36:01 [INFO]             'pre_post_process_quantization': True,\n",
      "2023-10-24 18:36:01 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2023-10-24 18:36:01 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2023-10-24 18:36:01 [INFO]             ],\n",
      "2023-10-24 18:36:01 [INFO]             'dedicated_qdq_pair': False,\n",
      "2023-10-24 18:36:01 [INFO]             'rtn_args': {\n",
      "2023-10-24 18:36:01 [INFO]             },\n",
      "2023-10-24 18:36:01 [INFO]             'awq_args': {\n",
      "2023-10-24 18:36:01 [INFO]             },\n",
      "2023-10-24 18:36:01 [INFO]             'gptq_args': {\n",
      "2023-10-24 18:36:01 [INFO]             },\n",
      "2023-10-24 18:36:01 [INFO]             'teq_args': {\n",
      "2023-10-24 18:36:01 [INFO]             }\n",
      "2023-10-24 18:36:01 [INFO]         },\n",
      "2023-10-24 18:36:01 [INFO]         'reduce_range': None,\n",
      "2023-10-24 18:36:01 [INFO]         'TuningCriterion': {\n",
      "2023-10-24 18:36:01 [INFO]             'max_trials': 100,\n",
      "2023-10-24 18:36:01 [INFO]             'objective': [\n",
      "2023-10-24 18:36:01 [INFO]                 'performance'\n",
      "2023-10-24 18:36:01 [INFO]             ],\n",
      "2023-10-24 18:36:01 [INFO]             'strategy': 'basic',\n",
      "2023-10-24 18:36:01 [INFO]             'strategy_kwargs': None,\n",
      "2023-10-24 18:36:01 [INFO]             'timeout': 0\n",
      "2023-10-24 18:36:01 [INFO]         },\n",
      "2023-10-24 18:36:01 [INFO]         'use_bf16': True\n",
      "2023-10-24 18:36:01 [INFO]     }\n",
      "2023-10-24 18:36:01 [INFO] }\n",
      "2023-10-24 18:36:01 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2023-10-24 18:36:01 [INFO] SmoothQuant args 'folding' is not set, it's False now.\n",
      "2023-10-24 18:36:02 [WARNING] \"slow_conv2d_cpu\" not implemented for 'Half'\n",
      "2023-10-24 18:36:02 [WARNING] Jit trace in GraphTrace failed, absorb layer detection is skipped\n",
      "2023-10-24 18:38:08 [INFO] Attention Blocks: 0\n",
      "2023-10-24 18:38:08 [INFO] FFN Blocks: 0\n",
      "2023-10-24 18:38:08 [INFO] Pass query framework capability elapsed time: 888.58 ms\n",
      "2023-10-24 18:38:08 [INFO] Do not evaluate the baseline and quantize the model with default configuration.\n",
      "2023-10-24 18:38:08 [INFO] Quantize the model with default config.\n",
      "2023-10-24 18:38:08 [INFO] |******Mixed Precision Statistics******|\n",
      "2023-10-24 18:38:08 [INFO] +---------------------+----------------+\n",
      "2023-10-24 18:38:08 [INFO] |       Op Type       |     Total      |\n",
      "2023-10-24 18:38:08 [INFO] +---------------------+----------------+\n",
      "2023-10-24 18:38:08 [INFO] +---------------------+----------------+\n",
      "2023-10-24 18:38:08 [INFO] Pass quantize model elapsed time: 9.01 ms\n",
      "2023-10-24 18:38:08 [INFO] Save tuning history to D:\\anaconda3\\jupyter notebook dir\\nc_workspace\\2023-10-24_18-23-32\\./history.snapshot.\n",
      "2023-10-24 18:38:08 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2023-10-24 18:38:08 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2023-10-24 18:38:08 [INFO] Save deploy yaml to D:\\anaconda3\\jupyter notebook dir\\nc_workspace\\2023-10-24_18-23-32\\deploy.yaml\n",
      "2023-10-24 18:38:09 [INFO] Save config file and weights of quantized model to D:\\anaconda3\\jupyter notebook dir\\output.\n"
     ]
    }
   ],
   "source": [
    "from neural_compressor import quantization\n",
    "from neural_compressor.config import PostTrainingQuantConfig\n",
    "\n",
    "recipes = {\n",
    "    \"smooth_quant\": True,\n",
    "    \"smooth_quant_args\": {\n",
    "        \"alpha\": 0.5,\n",
    "    },  # default value is 0.5\n",
    "    \"fast_bias_correction\": False,\n",
    "    \"max_trial\": 10000,\n",
    "    \"time_out\": 1000\n",
    "}\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "conf = (\n",
    "    PostTrainingQuantConfig(recipes=recipes)\n",
    ")  # default approach is \"auto\", you can set \"dynamic\":PostTrainingQuantConfig(approach=\"dynamic\")\n",
    "q_model = quantization.fit(\n",
    "    model=model,\n",
    "    conf=conf,\n",
    "    calib_dataloader=dataloader,\n",
    ")\n",
    "q_model.save(\"./output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('OpenGL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "66de5fe190df547b265682deb80fb4c823ba8ba09ea45715f4c1bd4bf4da77cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
